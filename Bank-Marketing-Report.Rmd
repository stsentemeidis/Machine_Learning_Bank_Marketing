---
title: "Predicting Term Deposits"
author: "MBD | ADVANCED R | June 2019"
always_allow_html: yes
output:
  html_document:
    theme: yeti
    code_folding: 'none' 
  github_document: default
params: 
  shiny: TRUE
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load Libraries, echo = FALSE, include = FALSE}
source('scripts/install_packages.R')

if (is.null(webshot:::find_phantom())) {
  webshot::install_phantomjs()
}
```

``` {r Load Prepared Data, echo = FALSE}
load('data_output/RMarkdown_Objects.RData')
```

``` {r Palettes, echo = FALSE}
BarFillColor <- "#330066"
HBarFillColor <- "#000099"
BarLineColor <- "#FFFAFA"
MissingColor <- "#FF6666"

color1 = 'white'
color2 = 'black'
color3 = 'black'
color4 = 'darkorchid3'
font1 = 'Impact'
font2 = 'Helvetica'
```

</br>

***

## Bank Marketing Dataset  

The *Bank Marketing* dataset contains the **direct marketing campaigns of a Portuguese banking institution**. The original dataset can be found on [Kaggle](https://www.kaggle.com/henriqueyamahata/bank-marketing).  

All the files of this project are saved in a [GitHub repository](https://github.com/ashomah/Bank-Marketing).  

The dataset consists in:  

* **Train Set** with `r format(nrow(raw_train), big.mark=',')` observations with `r length(raw_train)-1` features and the target `y`.  
* **Test Set** with `r format(nrow(raw_test), big.mark=',')` observations with `r length(raw_test)` features. The `y` column will be added to the Test Set, with NAs, to ease the pre-processing stage.  

This project aims to predict if a customer will subscribe to a bank term deposit, based on its features and call history of previous marketing campaigns.  

</br>

***

## Packages  

<span style="color:red">This analysis requires these R packages:</span>  

* Data Manipulation: `data.table`, `dplyr`, `tibble`, `tidyr`  
    
* Plotting: `corrplot`, `GGally`, `ggmap`, `ggplot2`, `grid`, `gridExtra`  
    
* Machine Learning: `caret`, `dbscan`, `glmnet`, `leaderCluster`, `MLmetrics`, `ranger`, `xgboost`  

* Multithreading: `doMC`, `doParallel`, `factoextra`, `foreach`, `parallel`  

* Reporting: `kableExtra`, `knitr`, `RColorBrewer`, `shiny`, and... `beepr`.  

These packages are installed and loaded if necessary by the main script.

</br>

***
 
## Data Loading  

The data seems to be pretty clean, the variables being a combination of integers and factors with no null values.  

``` {r NAs, echo = FALSE, collapse=TRUE}
# Check if contains NAs ----
na_count <-
  sapply(raw_train, function(y)
    sum(length(which(is.na(
      y
    )))))
na_count <- data.frame(na_count)
na_count$perc <- round(na_count$na_count / nrow(raw_train) * 100, 2)
print(paste0(nrow(na_count[na_count$na_count != 0,]), ' columns of the Train Set have NAs.'))

na_count <-
  sapply(raw_test, function(y)
    sum(length(which(is.na(
      y
    )))))
na_count <- data.frame(na_count)
na_count$perc <- round(na_count$na_count / nrow(raw_test) * 100, 2)
print(paste0(nrow(na_count[na_count$na_count != 0,]), ' columns of the Test Set have NAs.'))
```

</br>

As this analysis is a classification, the target `y` has to be set as factor. The structures of the datasets after initial preparation are:  

``` {r Structure Train, echo = FALSE, collapse = TRUE}
str_train <- capture.output(str(bank_train))
cat('Structure of the Train Set:')
cat(str_train, sep='\n')
```

``` {r Structure Test, echo = FALSE, collapse = TRUE}
str_test <- capture.output(str(bank_test))
cat('Structure of the Test Set:')
cat(str_test, sep='\n')
```

</br>

***

## Exploratory Data Analysis  

The target of this analysis is the variable `y`. This boolean indicates whether the customer has acquiered a bank term deposit account. With `r format(length(bank_train[bank_train$y == 'No', 'y'])/nrow(bank_train)*100, nsmall = 1, digits=2)`% of the customers having subscribed to this product, we can say that our Train set is slightly unbalanced. We might want to try rebalancing our dataset later in this analysis, to ensure our model is performing properly for unknown data.  

The features of the dataset provide different type of information about the customers.  

</br>

* Variables giving **personal information** of the customers:  

  * **`age`** of the customer  
  Customers are between `r min(bank_train$age)` and `r max(bank_train$age)` years old, with a mean of `r mean(bank_train$age)` and a median of `r median(bank_train$age)`. The inter-quartile range is between `r quantile(bank_train$age, 0.25)` and `r quantile(bank_train$age, 0.75)`. We can also notice the presence of some outliers.  

  * **`job`** category of the customer  
  There are `r length(unique(bank_train$job))` categories of jobs with more than half belonging to `blue-collar`, `management` and `technicians`, followed by admin and services. Retired candidates form `r format(length(bank_train[bank_train$job == 'retired', 'job'])/nrow(bank_train)*100, digits=0, nsmall=0)`% of the dataset, self-emplyed and entrepreneur around 6% and unemployed, housemaid and students each around 2%. The candidate with unknow jobs form less than 1%.

  * **`marital`** status of the customer  
 `r format(length(bank_train[bank_train$marital == 'married', 'marital'])/nrow(bank_train)*100, digits=0, nsmall=0)`% are married, `r format(length(bank_train[bank_train$marital == 'single', 'marital'])/nrow(bank_train)*100, digits=0, nsmall=0)`% are single, the others are divorced.  

  * **`education`** level of the customer  
  `r format(length(bank_train[bank_train$education == 'secondary', 'education'])/nrow(bank_train)*100, digits=0, nsmall=0)`% of the customers went to secondary school, `r format(length(bank_train[bank_train$education == 'tertiary', 'marital'])/nrow(bank_train)*100, digits=0, nsmall=0)`% to tertiary school, `r format(length(bank_train[bank_train$education == 'primary', 'marital'])/nrow(bank_train)*100, digits=0, nsmall=0)`% to primary school. The education of the other customers remains unknown.  

</br>

* Variables related to **financial status** of the customers:  

  * **`default`** history  
  This boolean indicates if the customer has already defaulted. Only `r format(length(bank_train[bank_train$default == 1, 'default'])/nrow(bank_train)*100, digits=1, nsmall=1)`% of the customers have defaulted.  

  * **`balance`** of customer's account  
  The average yearly balance of the customer in euros. The variable is ranged from `r format(min(bank_train$balance), digits=0, nsmall=0, big.mark=',')` to `r format(max(bank_train$balance), digits=0, nsmall=0, big.mark=',')` with a mean of `r format(mean(bank_train$balance), digits=0, nsmall=0, big.mark=',')` and a median of `r format(median(bank_train$balance), digits=0, nsmall=0, big.mark=',')`. The data is highly right-skewed.  

  * **`housing` ** loan  
  This boolean indicates if the customer has a house loan. `r format(length(bank_train[bank_train$housing == 1, 'housing'])/nrow(bank_train)*100, digits=0, nsmall=0)`% of the customers have one.  

  * **`loan`**  
  This boolean indicates if the customer has a personal loan. `r format(length(bank_train[bank_train$loan == 1, 'loan'])/nrow(bank_train)*100, digits=0, nsmall=0)`% of the customers have one.  

</br>

* Variables related to **campaign interactions** with the customer:  

  * **`contact`** mode  
  How the customer was contacted, with `r format(length(bank_train[bank_train$contact == 'cellular', 'contact'])/nrow(bank_train)*100, digits=0, nsmall=0)`% on their mobile phone, and `r format(length(bank_train[bank_train$contact == 'telephone', 'contact'])/nrow(bank_train)*100, digits=0, nsmall=0)`% ona landline.  

  * **`day`**  
  This indicates on which day of the month the customer was contacted.  

  * **`month`**  
  This indicates on which month the customer was contacted. May seems to be the peak month with `r format(length(bank_train[bank_train$month == 'may', 'month'])/nrow(bank_train)*100, digits=0, nsmall=0)`% of the calls followed by June, July, and August.  

  * **`duration`** of the call  
  Last phone call duration in seconds. The average call lasts around `r format(mean(bank_train$duration)/60, digits=0, nsmall=0)` minutes. However, the longest call lasts `r format(max(bank_train$duration)/60/60, digits=1, nsmall=1)` hours.

  * **`campaign`**  
  Number of times the customer was contacted *during* this campaign. Customers can have been contacted up to `r max(bank_train$campaign)` times. Around `r format(length(bank_train[bank_train$campaign <= 2, 'campaign'])/nrow(bank_train)*100, digits=0, nsmall=0)`% were contacted twice or less.  

  * **`pdays`**  
  Number of days that passed after the customer was last contacted from a previous campaign. `-1` means that the client was not previously contacted and this is his first campaign. Around `r format(length(bank_train[bank_train$pdays == -1, 'pdays'])/nrow(bank_train)*100, digits=0, nsmall=0)`% of the candidates are newly campaign clients. The average time elapsed is `r format(mean(bank_train$pdays), digits=0, nsmall=0)` days.  

  * **`previous`** contacts  
  Number of contacts performed *before* this campaign. Majority of the customers were never contacted. Other customers have been contacted `r format(mean(bank_train[bank_train$previous != -1, 'previous']), digits=0, nsmall=0)` times on average, with a maximum of `r format(max(bank_train[bank_train$previous != -1, 'previous']), digits=0, nsmall=0)` times.  

  * **`poutcome`**
  This categorical variable indicates the outcome from a previous campaign, whether it was a success or a failure. About `r format(length(bank_train[bank_train$poutcome == 'success', 'poutcome'])/nrow(bank_train)*100, digits=0, nsmall=0)`% of the customers answered positively to previous campaigns.  

</br>

<iframe src ="http://ashomah.shinyapps.io/plot_eda" height=800px width=100% position="center" frameborder="0" />

</br>

A quick look at the Test Set shows that the variables follow almost similar distriutions.  


</br>

***

## Analysis Method  

Flowchart  
Quick explanation  

</br>

***

## Data Preparation  

As the Test Set doesn't contain the feature `y`, it is necessary to randomly split the Train Set in two, with a 80|20 ratio:  

* **Train Set A**, which will be used to train our model.  
* **Train Set B**, which will be used to test our model and validate the performance of the model.  

These datasets are centered and scaled, using the `preProcess` function of the package `caret`. These transformations should improve the performance of linear models.  

Categorical variables are dummified, using the `  

</br>

***

## Cross-Validation Strategy  

To validate the stability of our models, we will apply a 10-fold cross-validation, repeated 3 times.  

</br>

***

## Baseline  

For our baseline, we used 3 algorithms.  

``` {r Baseline Results, echo=FALSE, message = FALSE, fig.align = 'center'}
to_display <-
  all_real_results[rownames(all_real_results) %in% c(
    'Logistic Reg. baseline',
    'XGBoost baseline',
    'Ranger baseline'
  ),]


to_display[order(to_display$Sensitivity, decreasing = TRUE), ] %>%
  rownames_to_column('Model') %>%
  mutate(
    Sensitivity = cell_spec(
      format(Sensitivity, nsmall = 7),
      color = ifelse(order(Sensitivity, decreasing = TRUE) <= 1, 'white', 'ghostwhite'),
      font_size = ifelse(order(Sensitivity, decreasing = TRUE) <= 1, 12, 11),
      background = spec_color(
        order(Sensitivity, decreasing = TRUE),
        option = 'D',
        begin = 0.50,
        end = 0.98,
        direction = 1
      ),
      bold = ifelse(order(Sensitivity, decreasing = TRUE) <= 1, TRUE, FALSE)
    )
  ) %>%
  kable(escape = FALSE, align = 'r') %>% kable_styling(bootstrap_options = c('hover', 'condensed'))
```

</br>

***

## Feature Engineering  

FRANCESCA

``` {r Feature Clustering Results, echo=FALSE, message = FALSE, fig.align = 'center'}
to_display <-
  all_real_results[rownames(all_real_results) %in% c(
    'Logistic Reg. baseline',
    'XGBoost baseline',
    'Ranger baseline',
    'Logistic Reg. FE1 Clustering',
    'XGBoost FE1 Clustering',
    'Ranger FE1 Clustering'
  ),]

to_display[order(to_display$Sensitivity, decreasing = TRUE), ] %>%
  rownames_to_column('Model') %>%
  mutate(
    Sensitivity = cell_spec(
      format(Sensitivity, nsmall = 7),
      color = ifelse(order(Sensitivity, decreasing = TRUE) <= 3, 'white', 'ghostwhite'),
      font_size = ifelse(order(Sensitivity, decreasing = TRUE) <= 3, 12, 11),
      background = spec_color(
        order(Sensitivity, decreasing = TRUE),
        option = 'D',
        begin = 0.50,
        end = 0.98,
        direction = 1
      ),
      bold = ifelse(order(Sensitivity, decreasing = TRUE) <= 3, TRUE, FALSE)
    )
  ) %>%
  kable(escape = FALSE, align = 'r') %>% kable_styling(bootstrap_options = c('hover', 'condensed'))
```



``` {r Feature Binning Results, echo=FALSE, message = FALSE, fig.align = 'center'}
to_display <-
  all_real_results[rownames(all_real_results) %in% c(
    'Logistic Reg. baseline',
    'XGBoost baseline',
    'Logistic Reg. FE1 Clustering',
    'Logistic Reg. FE2 Binning',
    'XGBoost FE2 Binning',
    'Ranger FE2 Binning'
  ),]

to_display[order(to_display$Sensitivity, decreasing = TRUE), ] %>%
  rownames_to_column('Model') %>%
  mutate(
    Sensitivity = cell_spec(
      format(Sensitivity, nsmall = 7),
      color = ifelse(order(Sensitivity, decreasing = TRUE) <= 3, 'white', 'ghostwhite'),
      font_size = ifelse(order(Sensitivity, decreasing = TRUE) <= 3, 12, 11),
      background = spec_color(
        order(Sensitivity, decreasing = TRUE),
        option = 'D',
        begin = 0.50,
        end = 0.98,
        direction = 1
      ),
      bold = ifelse(order(Sensitivity, decreasing = TRUE) <= 3, TRUE, FALSE)
    )
  ) %>%
  kable(escape = FALSE, align = 'r') %>% kable_styling(bootstrap_options = c('hover', 'condensed'))
```


</br>

***

## Feature Selection with Lasso and RFE  

NAYLA

DISPLAY VARIMP
LIST OF DELETED VAR

``` {r Lasso, echo=FALSE, message = FALSE, fig.height=8, fig.width=10, fig.align='center', collapse = TRUE}
print(
  paste0(
    'The Lasso Regression selected ',
    length(varsSelected),
    ' variables, and rejected ',
    length(varsNotSelected),
    ' variables.'
  )
)

kable(data.frame(matrix(
  c(sort(as.vector(varsNotSelected)), '', '', ''),
  nrow = 13, ncol = 5, byrow = TRUE
)), 
col.names = c('Rejected Features', '', '', '', ''),
align = 'l') %>% kable_styling(bootstrap_options = c('hover', 'condensed'))
```

``` {r RFE Variables, echo=FALSE, message = FALSE, fig.height=8, fig.width=10, fig.align='center', collapse = TRUE}
kable(
  data.frame(matrix(
    c(sort(as.vector(var_sel_rfe$Variables)), '', '', '', ''),
    nrow = 6,
    ncol = 5,
    byrow = TRUE
  )),
  col.names = c('Selected Features', '', '', '', ''),
  align = 'l'
) %>%
  kable_styling(bootstrap_options = c('hover', 'condensed'))
```



</br>

***

## Tuning  

``` {r Feature Tuning, echo=FALSE, message = FALSE, fig.align = 'center'}
to_display <-
  all_real_results[rownames(all_real_results) %in% c(
    'Logistic Reg. baseline',
    'Logistic Reg. FE1 Clustering',
    'Logistic Reg. FE2 Binning'
  ),]

to_display[order(to_display$Sensitivity, decreasing = TRUE), ] %>%
  rownames_to_column('Model') %>%
  mutate(
    Sensitivity = cell_spec(
      format(Sensitivity, nsmall = 7),
      color = ifelse(order(Sensitivity, decreasing = TRUE) <= 3, 'white', 'ghostwhite'),
      font_size = ifelse(order(Sensitivity, decreasing = TRUE) <= 3, 12, 11),
      background = spec_color(
        order(Sensitivity, decreasing = TRUE),
        option = 'D',
        begin = 0.50,
        end = 0.98,
        direction = 1
      ),
      bold = ifelse(order(Sensitivity, decreasing = TRUE) <= 3, TRUE, FALSE)
    )
  ) %>%
  kable(escape = FALSE, align = 'r') %>% kable_styling(bootstrap_options = c('hover', 'condensed'))
```



</br>

***

## Final Model  

The best model for...  


<iframe src ="http://ashomah.shinyapps.io/model_dash" height=900px width=100% position="center" frameborder="0" />


<br><br>

***

###### *Nayla Fakhoury | Martin Hofbauer | Andres Llerena | Francesca Manoni | Paul Jacques-Mignault | Ashley O'Mahony | Stavros Tsentemeidis*
###### *O17 (Group G) | Master in Big Data and Business Analytics | Oct 2018 Intake | IE School of Human Sciences and Technology*

***















